{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.nodeproppred import PygNodePropPredDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/accl-ros/anaconda3/envs/myenv/lib/python3.12/site-packages/ogb/nodeproppred/dataset_pyg.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    }
   ],
   "source": [
    "dataset = PygNodePropPredDataset(name='ogbn-mag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: kernel kernelspec migrate run troubleshoot trust\n",
      "\n",
      "Jupyter command `jupyter-nbconvert` not found.\n"
     ]
    }
   ],
   "source": [
    "# Clear outputs in-place to shrink notebook size\n",
    "!jupyter nbconvert --clear-output --inplace \"Heterogenous graph transformer.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('author',\n",
       "  'affiliated_with',\n",
       "  'institution'): tensor([[      0,       1,       2,  ..., 1134645, 1134647, 1134648],\n",
       "         [    845,     996,    3197,  ...,    5189,    4668,    4668]]),\n",
       " ('author',\n",
       "  'writes',\n",
       "  'paper'): tensor([[      0,       0,       0,  ..., 1134647, 1134648, 1134648],\n",
       "         [  19703,  289285,  311768,  ...,  657395,  671118,  719594]]),\n",
       " ('paper',\n",
       "  'cites',\n",
       "  'paper'): tensor([[     0,      0,      0,  ..., 736388, 736388, 736388],\n",
       "         [    88,  27449, 121051,  ..., 421711, 427339, 439864]]),\n",
       " ('paper',\n",
       "  'has_topic',\n",
       "  'field_of_study'): tensor([[     0,      0,      0,  ..., 736388, 736388, 736388],\n",
       "         [   145,   2215,   3205,  ...,  21458,  22283,  31934]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index_dict = data.edge_index_dict\n",
    "edge_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import math, copy, time\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1 = {'type': 'User', 'id': 'U1'}\n",
    "user2 = {'type': 'User', 'id': 'U2'}\n",
    "post1 = {'type': 'Post', 'id': 'P1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph():\n",
    "    def __init__(self):\n",
    "        super(Graph, self).__init__()\n",
    "        self.node_forward = defaultdict(lambda:{}) # {node1: {node2: edge1, node3: edge2}}\n",
    "        self.node_bacward = defaultdict(lambda:[]) # {node1: [node2, node3]}\n",
    "\n",
    "        self.node_features = defaultdict(lambda:[]) # {node1: [feat1, feat2]}\n",
    "        self.edge_list = defaultdict( #target_type\n",
    "                            lambda: defaultdict(  #source_type\n",
    "                                lambda: defaultdict(  #relation_type\n",
    "                                    lambda: defaultdict(  #target_id\n",
    "                                        lambda: defaultdict( #source_id(\n",
    "                                            lambda: int # time\n",
    "                                        ))))) #\n",
    "        self.times = {} # {time: {edge_index: time}}\n",
    "    def add_node(self,node):\n",
    "        nfl=self.node_forward[node['type']] # how? why? \n",
    "        if node['id'] not in nfl:\n",
    "            self.node_bacward[node['type']] += [node]\n",
    "            ser = len(nfl)\n",
    "            nfl[node['id']] = ser\n",
    "            return ser\n",
    "        return nfl[node['id']]\n",
    "    def add_edge(self, source_node, target_node, time = None, relation_type = None, directed = True):\n",
    "        edge = [self.add_node(source_node), self.add_node(target_node)]\n",
    "        '''\n",
    "            Add bi-directional edges with different relation type\n",
    "        '''\n",
    "        self.edge_list[target_node['type']][source_node['type']][relation_type][edge[1]][edge[0]] = time\n",
    "        if directed:\n",
    "            self.edge_list[source_node['type']][target_node['type']]['rev_' + relation_type][edge[0]][edge[1]] = time\n",
    "        else:\n",
    "            self.edge_list[source_node['type']][target_node['type']][relation_type][edge[0]][edge[1]] = time\n",
    "        self.times[time] = True\n",
    "    def update_node(self, node):\n",
    "        nbl = self.node_bacward[node['type']]\n",
    "        ser = self.add_node(node)\n",
    "        for k in node:\n",
    "            if k not in nbl[ser]:\n",
    "                nbl[ser][k] = node[k]\n",
    "    def get_meta_graph(self):\n",
    "        #types = self.get_types()\n",
    "        metas = []\n",
    "        for target_type in self.edge_list:\n",
    "            for source_type in self.edge_list[target_type]:\n",
    "                for r_type in self.edge_list[target_type][source_type]:\n",
    "                    metas += [(target_type, source_type, r_type)]\n",
    "        return metas\n",
    "    def get_types(self):\n",
    "        return list(self.node_feature.keys())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.Graph.__init__.<locals>.<lambda>()>,\n",
       "            {'Post': defaultdict(<function __main__.Graph.__init__.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'User': defaultdict(<function __main__.Graph.__init__.<locals>.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                                      {'authored': defaultdict(<function __main__.Graph.__init__.<locals>.<lambda>.<locals>.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                                                   {0: defaultdict(<function __main__.Graph.__init__.<locals>.<lambda>.<locals>.<lambda>.<locals>.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                                                                {0: 1})})})}),\n",
       "             'User': defaultdict(<function __main__.Graph.__init__.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'Post': defaultdict(<function __main__.Graph.__init__.<locals>.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                                      {'rev_authored': defaultdict(<function __main__.Graph.__init__.<locals>.<lambda>.<locals>.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                                                   {0: defaultdict(<function __main__.Graph.__init__.<locals>.<lambda>.<locals>.<lambda>.<locals>.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                                                                {0: 1})})})})})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph=Graph()\n",
    "graph.add_node(user1)\n",
    "graph.add_node(user2)\n",
    "# Step 1: Add initial nodes\n",
    "user_node = {'type': 'User', 'id': 'U1', 'name': 'Alice'}\n",
    "post_node = {'type': 'Post', 'id': 'P1', 'title': 'Graph Theory'}\n",
    "graph.add_edge(source_node=user_node, target_node=post_node, time=1, relation_type='authored', directed=True)\n",
    "\n",
    "graph.edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Post', 'User', 'authored'), ('User', 'Post', 'rev_authored')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_meta_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_user_node = {'type': 'User', 'id': 'U1', 'age': 30}\n",
    "graph.add_node(updated_user_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.Graph.__init__.<locals>.<lambda>()>,\n",
       "            {'User': {'U1': 0, 'U2': 1}, 'Post': {'P1': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.node_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.node_bacward['User'][0]['ppp'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "years=data.node_year['paper'].t().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "id\n",
      "age\n"
     ]
    }
   ],
   "source": [
    "for k in updated_user_node:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = data.node_year['paper'].t().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "edg   = graph.edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "edg   = graph.edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('author', 'affiliated_with', 'institution')\n",
      "('author', 'writes', 'paper')\n",
      "('paper', 'cites', 'paper')\n",
      "('paper', 'has_topic', 'field_of_study')\n"
     ]
    }
   ],
   "source": [
    "for key in data.edge_index_dict:\n",
    "    print(key)\n",
    "    edges = edge_index_dict[key]\n",
    "    s_type, r_type, t_type = key[0], key[1], key[2]\n",
    "    e_list = edg[t_type][s_type][r_type]\n",
    "    r_list = edg[s_type][t_type]['rev_' + r_type]\n",
    "    for s_id, t_id in edges.t().tolist():\n",
    "        year=None\n",
    "        if s_type == 'paper':\n",
    "            year = years[s_id]\n",
    "        elif t_type == 'paper':\n",
    "            year = years[t_id]\n",
    "        e_list[s_id][t_id] = year\n",
    "        r_list[t_id][s_id] = year\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: Post            | Nodes:        1 | Offset:        0\n",
      "Type: User            | Nodes:        2 | Offset:        1\n",
      "Type: author          | Nodes:  1134649 | Offset:        3\n",
      "Type: field_of_study  | Nodes:    59965 | Offset:  1134652\n",
      "Type: institution     | Nodes:     8740 | Offset:  1194617\n",
      "Type: paper           | Nodes:   736389 | Offset:  1203357\n",
      "\n",
      "Final Check:\n",
      "Total Features Rows: 1939746\n",
      "Total Node Type Rows: 1939746\n"
     ]
    }
   ],
   "source": [
    "# --- STEP 1: Accurate Node Counts ---\n",
    "all_node_types = sorted(list(all_types_in_edges))\n",
    "node_type_to_id = {ntype: i for i, ntype in enumerate(all_node_types)}\n",
    "\n",
    "x_list = []\n",
    "type_list = []\n",
    "offsets = {}\n",
    "curr_offset = 0\n",
    "\n",
    "for ntype in all_node_types:\n",
    "    # 1. Get the actual count of nodes for this type\n",
    "    # We check your graph.node_forward map first\n",
    "    num_nodes = len(graph.node_forward.get(ntype, {}))\n",
    "    \n",
    "    # 2. Safety check: If node_forward is empty, check the data dictionary\n",
    "    if num_nodes == 0 and ntype in data.num_nodes_dict:\n",
    "        num_nodes = data.num_nodes_dict[ntype]\n",
    "    \n",
    "    offsets[ntype] = curr_offset\n",
    "    \n",
    "    # 3. Create/Fetch features\n",
    "    if ntype == 'paper' and 'paper' in data.x_dict:\n",
    "        feats = data.x_dict['paper']\n",
    "    else:\n",
    "        # Every node MUST have a feature vector of the same width (128)\n",
    "        feats = torch.zeros((num_nodes, 128))\n",
    "    \n",
    "    # --- DEBUG PRINTS ---\n",
    "    # This helps you see if a type has 0 nodes, which might cause the error\n",
    "    print(f\"Type: {ntype:15} | Nodes: {num_nodes:8} | Offset: {curr_offset:8}\")\n",
    "    \n",
    "    x_list.append(feats)\n",
    "    # CRITICAL: type_list must have 'num_nodes' entries for THIS specific type\n",
    "    type_list.append(torch.full((num_nodes,), node_type_to_id[ntype], dtype=torch.long))\n",
    "    \n",
    "    curr_offset += num_nodes\n",
    "\n",
    "# --- STEP 2: Final Tensors ---\n",
    "x_all = torch.cat(x_list, dim=0).to(device)\n",
    "node_type = torch.cat(type_list, dim=0).to(device)\n",
    "\n",
    "# --- HUMAN CHECK ---\n",
    "# These two MUST be the same number. If they aren't, the mask will fail.\n",
    "print(f\"\\nFinal Check:\")\n",
    "print(f\"Total Features Rows: {x_all.size(0)}\")\n",
    "print(f\"Total Node Type Rows: {node_type.size(0)}\")\n",
    "\n",
    "if x_all.size(0) != node_type.size(0):\n",
    "    print(\"CRITICAL ERROR: Sizes still don't match! Check your num_nodes logic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Nodes: 1939746 | Sampled Nodes: 0\n",
      "Original Edges: 42222016 | Sampled Edges: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Select 10% of the Paper nodes\n",
    "paper_type_id = node_type_to_id['paper']\n",
    "all_paper_indices = torch.where(node_type == paper_type_id)[0]\n",
    "\n",
    "# Shuffle and pick 10%\n",
    "num_papers = len(all_paper_indices)\n",
    "sample_size = int(num_papers * 0.10)\n",
    "perm = torch.randperm(num_papers)\n",
    "sampled_paper_indices = all_paper_indices[perm[:sample_size]]\n",
    "\n",
    "# 2. Filter edges\n",
    "# We only keep edges where the destination (target) is one of our sampled papers\n",
    "# or the source is one of our sampled papers.\n",
    "mask = torch.isin(edge_index_all[0], sampled_paper_indices) | torch.isin(edge_index_all[1], sampled_paper_indices)\n",
    "\n",
    "sampled_edge_index = edge_index_all[:, mask]\n",
    "sampled_edge_type = edge_type_all[mask]\n",
    "\n",
    "# 3. Identify all unique nodes involved in these 10% edges\n",
    "relevant_nodes = torch.unique(sampled_edge_index)\n",
    "\n",
    "# 4. Create a mapping to shrink the node IDs (re-indexing)\n",
    "# This prevents the model from trying to allocate a 1.9M row matrix\n",
    "new_x = x_all[relevant_nodes]\n",
    "new_node_type = node_type[relevant_nodes]\n",
    "\n",
    "# Re-map the edge indices to the new smaller node set [0, len(relevant_nodes)]\n",
    "n_id_map = torch.full((x_all.size(0),), -1, device=device)\n",
    "n_id_map[relevant_nodes] = torch.arange(relevant_nodes.size(0), device=device)\n",
    "\n",
    "final_edge_index = n_id_map[sampled_edge_index]\n",
    "final_edge_type = sampled_edge_type\n",
    "\n",
    "print(f\"Original Nodes: {x_all.size(0)} | Sampled Nodes: {new_x.size(0)}\")\n",
    "print(f\"Original Edges: {edge_index_all.size(1)} | Sampled Edges: {final_edge_index.size(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Sampled Output shape: torch.Size([0, 349])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import softmax\n",
    "from torch_scatter import scatter_add\n",
    "\n",
    "class ScratchHGTConv(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, num_types, num_relations, n_heads=4):\n",
    "        super().__init__()\n",
    "        self.out_dim, self.n_heads = out_dim, n_heads\n",
    "        self.d_k = out_dim // n_heads\n",
    "        self.sqrt_dk = self.d_k ** 0.5\n",
    "        \n",
    "        self.k_linears = nn.ModuleList([nn.Linear(in_dim, out_dim) for _ in range(num_types)])\n",
    "        self.q_linears = nn.ModuleList([nn.Linear(in_dim, out_dim) for _ in range(num_types)])\n",
    "        self.v_linears = nn.ModuleList([nn.Linear(in_dim, out_dim) for _ in range(num_types)])\n",
    "        self.a_linears = nn.ModuleList([nn.Linear(out_dim, out_dim) for _ in range(num_types)])\n",
    "        self.norms = nn.ModuleList([nn.LayerNorm(out_dim) for _ in range(num_types)])\n",
    "        \n",
    "        self.relation_att = nn.Parameter(torch.Tensor(num_relations, n_heads, self.d_k, self.d_k))\n",
    "        self.relation_msg = nn.Parameter(torch.Tensor(num_relations, n_heads, self.d_k, self.d_k))\n",
    "        nn.init.xavier_uniform_(self.relation_att); nn.init.xavier_uniform_(self.relation_msg)\n",
    "\n",
    "    def forward(self, node_feat, node_type, edge_index, edge_type):\n",
    "        src, dst = edge_index\n",
    "        N = node_feat.size(0)\n",
    "        \n",
    "        k_all = torch.zeros(N, self.out_dim, device=node_feat.device)\n",
    "        q_all = torch.zeros(N, self.out_dim, device=node_feat.device)\n",
    "        v_all = torch.zeros(N, self.out_dim, device=node_feat.device)\n",
    "        \n",
    "        for t in range(len(self.k_linears)):\n",
    "            mask = (node_type == t)\n",
    "            if mask.any():\n",
    "                k_all[mask] = self.k_linears[t](node_feat[mask])\n",
    "                q_all[mask] = self.q_linears[t](node_feat[mask])\n",
    "                v_all[mask] = self.v_linears[t](node_feat[mask])\n",
    "\n",
    "        k, q, v = [x.view(-1, self.n_heads, self.d_k) for x in [k_all, q_all, v_all]]\n",
    "\n",
    "        # Attention calculation\n",
    "        k_rel = torch.einsum('ehd,ehdf->ehf', k[src], self.relation_att[edge_type])\n",
    "        att_score = (q[dst] * k_rel).sum(dim=-1) * (1.0 / self.sqrt_dk)\n",
    "        att_weight = softmax(att_score, dst, num_nodes=N)\n",
    "        \n",
    "        # Message calculation\n",
    "        v_rel = torch.einsum('ehd,ehdf->ehf', v[src], self.relation_msg[edge_type])\n",
    "        messages = (v_rel * att_weight.unsqueeze(-1)).reshape(-1, self.out_dim)\n",
    "        \n",
    "        aggr_out = scatter_add(messages, dst, dim=0, dim_size=N)\n",
    "        \n",
    "        final_out = aggr_out.clone()\n",
    "        for t in range(len(self.a_linears)):\n",
    "            mask = (node_type == t)\n",
    "            if mask.any():\n",
    "                final_out[mask] = self.norms[t](self.a_linears[t](aggr_out[mask]))\n",
    "        return final_out\n",
    "\n",
    "class ScratchHGTModel(nn.Module):\n",
    "    def __init__(self, num_types, num_relations, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
    "        self.conv1 = ScratchHGTConv(hidden_dim, hidden_dim, num_types, num_relations)\n",
    "        self.classifier = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x, node_type, edge_index, edge_type):\n",
    "        h = F.gelu(self.input_proj(x))\n",
    "        h = self.conv1(h, node_type, edge_index, edge_type)\n",
    "        return self.classifier(h)\n",
    "\n",
    "# --- RUNNING ---\n",
    "# Instantiate model with the same parameters\n",
    "model = ScratchHGTModel(\n",
    "    num_types=len(all_node_types),\n",
    "    num_relations=len(rel_map),\n",
    "    in_dim=128, \n",
    "    hidden_dim=128,\n",
    "    out_dim=dataset.num_classes\n",
    ").to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Pass the sampled data\n",
    "    output = model(new_x, new_node_type, final_edge_index, final_edge_type)\n",
    "    print(f\"Success! Sampled Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
